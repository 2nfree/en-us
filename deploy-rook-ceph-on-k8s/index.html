<!DOCTYPE html><html lang="en_US" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Deploy Rook Ceph On Kubernetes | Gengar's Pokeball</title><meta name="author" content="komorebi"><meta name="copyright" content="komorebi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="This document provides a method for installing a Ceph cluster in a Kubernetes cluster using Rook."><meta property="og:type" content="article"><meta property="og:title" content="Deploy Rook Ceph On Kubernetes"><meta property="og:url" content="https://blog.2nfree.com/en-us/deploy-rook-ceph-on-k8s/"><meta property="og:site_name" content="Gengar&#39;s Pokeball"><meta property="og:description" content="This document provides a method for installing a Ceph cluster in a Kubernetes cluster using Rook."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://blog.2nfree.com/en-us/images/avatar.png"><meta property="article:published_time" content="2023-02-17T15:20:34.000Z"><meta property="article:modified_time" content="2023-03-11T14:04:37.000Z"><meta property="article:author" content="komorebi"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Storage"><meta property="article:tag" content="Ceph"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://blog.2nfree.com/en-us/images/avatar.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Deploy Rook Ceph On Kubernetes",
  "url": "https://blog.2nfree.com/en-us/deploy-rook-ceph-on-k8s/",
  "image": "https://blog.2nfree.com/en-us/images/avatar.png",
  "datePublished": "2023-02-17T15:20:34.000Z",
  "dateModified": "2023-03-11T14:04:37.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "komorebi",
      "url": "https://blog.2nfree.com/en-us/"
    }
  ]
}</script><link rel="shortcut icon" href="/en-us/images/logo.svg"><link rel="canonical" href="https://blog.2nfree.com/en-us/deploy-rook-ceph-on-k8s/"><link rel="preconnect"><link rel="stylesheet" href="/en-us/css/index.css?v=5.3.2"><link rel="stylesheet" href="/en-us/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css?v=6.7.2"><script>(()=>{const e={set:(e,t,o)=>{if(!o)return;const a=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:a}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return o;localStorage.removeItem(e)}};window.btf={saveToLocal:e,getScript:(e,t={})=>new Promise((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,Object.entries(t).forEach(([e,t])=>n.setAttribute(e,t)),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)}),getCSS:(e,t)=>new Promise((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)}),addGlobalFn:(e,t,o=!1,a=window)=>{if(e.startsWith("pjax"))return;const n=a.globalFn||{};n[e]=n[e]||{},n[e][o||Object.keys(n[e]).length]=t,a.globalFn=n}};const t=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},o=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","ffffff")};btf.activateDarkMode=t,btf.activateLightMode=o;const a=e.get("theme");"dark"===a?t():"light"===a&&o();const n=e.get("aside-status");void 0!==n&&document.documentElement.classList.toggle("hide-aside","hide"===n);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script>const GLOBAL_CONFIG={root:"/en-us/",algolia:void 0,localSearch:{path:"/en-us/search.xml",preload:!0,top_n_per_article:1,unescape:!1,languages:{hits_empty:"No results found for: ${query}",hits_stats:"${hits} articles found"}},translate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200,highlightFullpage:!1,highlightMacStyle:!0},copy:{success:"Copy Successful",error:"Copy Failed",noSupport:"Browser Not Supported"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"Just now",min:"minutes ago",hour:"hours ago",day:"days ago",month:"months ago"},copyright:void 0,lightbox:"null",Snackbar:void 0,infinitegrid:{js:"/en-us/pluginsSrc/@egjs/infinitegrid/dist/infinitegrid.min.js?v=4.12.0",buttonText:"Load More"},isPhotoFigcaption:!1,islazyloadPlugin:!1,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Deploy Rook Ceph On Kubernetes",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/en-us/atom.xml" title="Gengar's Pokeball" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/en-us/images/avatar.png" onerror='this.onerror=null,this.src="/en-us/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/en-us/archives/"><div class="headline">Articles</div><div class="length-num">30</div></a><a href="/en-us/tags/"><div class="headline">Tags</div><div class="length-num">17</div></a><a href="/en-us/categories/"><div class="headline">Categories</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/en-us/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/links/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-language"></i><span> Language</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="https://blog.2nfree.com"><i class="fa-fw fa-solid fa-language"></i><span> 简体中文</span></a></li><li><a class="site-page child" href="https://blog.2nfree.com/en-us"><i class="fa-fw fa-solid fa-language"></i><span> English</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/images/background-light.webp)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/en-us/"><img class="site-icon" src="/en-us/images/logo.svg" alt="Logo"><span class="site-name">Gengar's Pokeball</span></a><a class="nav-page-title" href="/en-us/"><span class="site-name">Deploy Rook Ceph On Kubernetes</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/en-us/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/links/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/en-us/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-language"></i><span> Language</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="https://blog.2nfree.com"><i class="fa-fw fa-solid fa-language"></i><span> 简体中文</span></a></li><li><a class="site-page child" href="https://blog.2nfree.com/en-us"><i class="fa-fw fa-solid fa-language"></i><span> English</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Deploy Rook Ceph On Kubernetes</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-02-17T15:20:34.000Z" title="Created 2023-02-17 23:20:34">2023-02-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-03-11T14:04:37.000Z" title="Updated 2023-03-11 22:04:37">2023-03-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/en-us/categories/CloudNative/">CloudNative</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">1.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>9mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:100,&quot;messagePrev&quot;:&quot;This article was updated&quot;,&quot;messageNext&quot;:&quot;days ago, Please verify that the information is still up-to-date.&quot;,&quot;postUpdate&quot;:&quot;2023-03-11 22:04:37&quot;}" hidden></div><div class="note red flat"><p>当前文档有中文版本：<a href="/deploy-rook-ceph-on-k8s/">点击这里切换到中文</a>.</p></div><h1 id="Foreword"><a href="#Foreword" class="headerlink" title="Foreword"></a>Foreword</h1><h2 id="Persistent-Storage"><a href="#Persistent-Storage" class="headerlink" title="Persistent Storage"></a>Persistent Storage</h2><p>Persistent storage for containers is a crucial means of preserving the storage state of containers. Storage plugins mount a remote data volume in the container, based on a network or other mechanisms, ensuring that files created inside the container are actually stored on a remote storage server or distributed across multiple nodes. This way, there is no binding relationship with the current host machine.</p><p>As a result, no matter which host you start a new container on, you can request to mount the specified persistent storage volume, thereby accessing the data stored in the volume.</p><p>Due to Kubernetes’ loosely coupled design, most storage solutions, such as Ceph, GlusterFS, NFS, and others, can provide persistent storage capabilities for Kubernetes.</p><h2 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a>Ceph</h2><p>Ceph is a distributed storage system that provides file, block and object storage and is deployed in large scale production clusters.</p><p>Official website: <a target="_blank" rel="noopener" href="https://ceph.io/">ceph.io</a></p><h2 id="Rook"><a href="#Rook" class="headerlink" title="Rook"></a>Rook</h2><p>Rook is an open source cloud-native storage orchestrator, providing the platform, framework, and support for Ceph storage to natively integrate with cloud-native environments.</p><p>Rook automates deployment and management of Ceph to provide self-managing, self-scaling, and self-healing storage services. The Rook operator does this by building on Kubernetes resources to deploy, configure, provision, scale, upgrade, and monitor Ceph.</p><p>Official website: <a target="_blank" rel="noopener" href="https://rook.io/">rook.io</a></p><p>GitHub: <a target="_blank" rel="noopener" href="https://github.com/rook/rook">rook&#x2F;rook</a></p><h1 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a>Prepare</h1><div class="note blue flat"><p>PS：Before installing Rook, ensure that the Kubernetes cluster has at least three available nodes to meet Ceph’s high availability requirements.</p></div><h2 id="Disk"><a href="#Disk" class="headerlink" title="Disk"></a>Disk</h2><p>Rook uses Ceph to create distributed storage services. During the initial installation, Rook automatically detects all the disks on the nodes and creates OSD services to manage them.</p><p>Rook monitors and discovers available devices based on the following criteria: The device has no partitions and does not have a formatted file system.</p><p>Rook will not use devices that do not meet the above criteria. Additionally, you can modify the configuration file to specify which nodes or devices will be used.</p><p>The following steps are for installing Rook on Kubernetes (CentOS):</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check disk status</span></span><br><span class="line">lsblk -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize Disk</span></span><br><span class="line">yum install gdisk -y</span><br><span class="line">sgdisk --zap-all /dev/vdb</span><br><span class="line"><span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=<span class="string">&quot;/dev/vdb&quot;</span> bs=1M count=100 oflag=direct,dsync</span><br><span class="line">blkdiscard /dev/vdb</span><br><span class="line">partprobe /dev/vdb</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install lvm2</span></span><br><span class="line">yum install lvm2 -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable rbd module</span></span><br><span class="line">modprobe rbd</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/rc.sysinit &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">#!/bin/bash</span></span><br><span class="line"><span class="string">for file in /etc/sysconfig/modules/*.modules</span></span><br><span class="line"><span class="string">do</span></span><br><span class="line"><span class="string">  [ -x \$file ] &amp;&amp; \$file</span></span><br><span class="line"><span class="string">done</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/sysconfig/modules/rbd.modules &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">modprobe rbd</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">chmod</span> 755 /etc/sysconfig/modules/rbd.modules</span><br><span class="line">lsmod |grep rbd</span><br></pre></td></tr></table></figure><h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><h2 id="Deploy-Rook-Operator"><a href="#Deploy-Rook-Operator" class="headerlink" title="Deploy Rook Operator"></a>Deploy Rook Operator</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /data/packages</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> --single-branch --branch release-1.9 https://github.com/rook/rook.git</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /data/packages/rook/deploy/examples</span><br><span class="line"></span><br><span class="line"><span class="comment"># apply common manifests</span></span><br><span class="line">kubectl create -f crds.yaml</span><br><span class="line">kubectl create -f common.yaml</span><br></pre></td></tr></table></figure><ul><li>This file is a Kubernetes manifests file, and you can directly use Kubernetes commands to deploy all the resources defined in the file to the cluster.</li><li>There is only one point to note: if you want to install Rook and the corresponding Ceph containers into a specific project, it is recommended to first create the project and the namespace.</li><li>The common file resources will automatically create a namespace called <code>rook-ceph</code>, and all subsequent resources and containers will be installed within this namespace.</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Modify the `operator.yaml` configuration to enable automatic disk discovery.</span></span><br><span class="line"><span class="comment"># By default, automatic discovery is disabled. Once enabled, Rook will automatically create OSDs when new raw disk devices are connected.</span></span><br><span class="line"><span class="comment"># However, note that unmounting a disk will not remove the OSD.</span></span><br><span class="line">ROOK_ENABLE_DISCOVERY_DAEMON: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install operator</span></span><br><span class="line">kubectl create -f operator.yaml</span><br></pre></td></tr></table></figure><ul><li>The operator is the core of the entire Rook system, and all subsequent functions such as cluster creation, automatic orchestration, and expansion are implemented based on the operator.</li><li>After the installation is complete, you need to wait for all operators to be running normally before proceeding with the installation of the Ceph distributed cluster.</li></ul><p>Check the installation status by running the following command, and wait until all the pods are in the Running state before proceeding to the next step</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n rook-ceph get pod</span><br></pre></td></tr></table></figure><p>This will display the status of all pods in the rook-ceph namespace. Ensure all pods are in the Running state before continuing with the Ceph distributed cluster installation.</p><h2 id="Deploy-rook-ceph"><a href="#Deploy-rook-ceph" class="headerlink" title="Deploy rook-ceph"></a>Deploy rook-ceph</h2><p>With a single YAML orchestration file, you can manage the deployment of the entire Ceph component, including disk configuration, cluster setup, and other related operations.</p><p>By applying this YAML file with the kubectl command, you can automatically deploy and configure the entire Ceph system within your Kubernetes environment. Here’s a simplified command for applying the file:</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f cluster.yaml</span><br></pre></td></tr></table></figure><p>The OSD containers must exist and be running properly. If all the OSD pods are running successfully, the cluster installation is considered successful.</p><p>To verify the status of the OSD pods, use the following command:</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n rook-ceph get pod</span><br></pre></td></tr></table></figure><p>Check that all OSD pods (e.g., osd-0, osd-1, osd-2, or any others based on your configuration) are in the Running state. If all these OSD pods are running without any issues, such as CrashLoopBackOff or Error, the Ceph cluster installation can be deemed successful.</p><h2 id="Check"><a href="#Check" class="headerlink" title="Check"></a>Check</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Apply toolbox pod</span></span><br><span class="line">kubectl apply -f toolbox.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Enter the toolbox pod</span></span><br><span class="line">kubectl -n rook-ceph <span class="built_in">exec</span> -it deploy/rook-ceph-tools -- bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check</span></span><br><span class="line">ceph status</span><br><span class="line">ceph osd status</span><br><span class="line">ceph <span class="built_in">df</span> </span><br><span class="line">rados <span class="built_in">df</span></span><br></pre></td></tr></table></figure><h2 id="StorageClass"><a href="#StorageClass" class="headerlink" title="StorageClass"></a>StorageClass</h2><p>After the cluster setup is complete, the next step is to create storage. Currently, Ceph supports three types of storage: block storage, file system storage, and object storage.</p><ul><li><p><strong>Block Storage</strong>: This is the storage solution officially integrated with Kubernetes and is considered the most stable option. However, block storage currently does not support multi-host read-write access (it is limited to <code>RWO</code> - ReadWriteOnce).</p></li><li><p><strong>File System Storage</strong>: It supports multi-host access and offers good performance, making it suitable for scenarios requiring concurrent access across multiple nodes.</p></li><li><p><strong>Object Storage</strong>: Due to its poor I&#x2F;O performance, it is generally not recommended for pvc use cases.</p></li></ul><p>Once the storage system is created, you must add a <strong>StorageClass</strong> for the system. Only then can the Ceph storage be used directly by the Kubernetes cluster through the Kubernetes storage class.</p><p>Given the various options and detailed configuration required, it is recommended to refer to the official Rook documentation for guidance: <a target="_blank" rel="noopener" href="https://rook.github.io/docs/rook/latest-release/Storage-Configuration/Block-Storage-RBD/block-storage/">Storage Configuration</a>.</p><p>PS：It is recommended to use the <strong>XFS</strong> file system instead of <strong>EXT4</strong>, as EXT4 creates a <code>lost+found</code> directory after formatting. Some containers, such as MySQL, require the mounted data disk to be completely empty. If using EXT4 is necessary, you can choose to mount it to a parent directory to avoid conflicts caused by the <code>lost+found</code> folder.</p><p>Using <strong>XFS</strong> ensures a cleaner mount point without the need for extra adjustments, making it more suitable for containers that expect an empty volume.</p><h3 id="CephFS"><a href="#CephFS" class="headerlink" title="CephFS"></a>CephFS</h3><h4 id="Create-a-File-System-Pool"><a href="#Create-a-File-System-Pool" class="headerlink" title="Create a File System Pool"></a>Create a File System Pool</h4><p>To create a file system pool in Ceph, especially for testing purposes, you can use a default configuration. For production environments, it is recommended to adjust the number of replicas (shards) to 2 or 3 for better data redundancy.</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephFilesystem</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">metadataPool:</span></span><br><span class="line">    <span class="attr">replicated:</span></span><br><span class="line">      <span class="comment"># replicas 1 for test</span></span><br><span class="line">      <span class="attr">size:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">requireSafeReplicaSize:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">dataPools:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">replicated</span></span><br><span class="line">      <span class="attr">failureDomain:</span> <span class="string">osd</span></span><br><span class="line">      <span class="attr">replicated:</span></span><br><span class="line">        <span class="comment"># replicas 1 for test</span></span><br><span class="line">        <span class="attr">size:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">requireSafeReplicaSize:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">preserveFilesystemOnDelete:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">metadataServer:</span></span><br><span class="line">    <span class="attr">activeCount:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">activeStandby:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f ceph-filesystem.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check pod status</span></span><br><span class="line">kubectl -n rook-ceph get pod -l app=rook-ceph-mds</span><br><span class="line"></span><br><span class="line"><span class="comment"># Enter the toolbox pod</span></span><br><span class="line">kubectl -n rook-ceph <span class="built_in">exec</span> -it deploy/rook-ceph-tools -- bash</span><br><span class="line">ceph status</span><br></pre></td></tr></table></figure><h4 id="Create-StorageClass"><a href="#Create-StorageClass" class="headerlink" title="Create StorageClass"></a>Create StorageClass</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rook-cephfs</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rook-ceph.cephfs.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">clusterID:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">fsName:</span> <span class="string">cephfs</span></span><br><span class="line">  <span class="attr">pool:</span> <span class="string">cephfs-replicated</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">rook-csi-cephfs-provisioner</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/controller-expand-secret-name:</span> <span class="string">rook-csi-cephfs-provisioner</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/controller-expand-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">rook-csi-cephfs-node</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"><span class="attr">allowVolumeExpansion:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># apply</span></span><br><span class="line">kubectl apply -f storageclass-cephfs.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># check</span></span><br><span class="line">kubectl get sc</span><br></pre></td></tr></table></figure><h4 id="Set-Default-StorageClass"><a href="#Set-Default-StorageClass" class="headerlink" title="Set Default StorageClass"></a>Set Default StorageClass</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl patch sc rook-cephfs -p <span class="string">&#x27;&#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;:&#123;&quot;storageclass.kubernetes.io/is-default-class&quot;:&quot;true&quot;&#125;&#125;&#125;&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="Create-Test-PVC"><a href="#Create-Test-PVC" class="headerlink" title="Create Test PVC"></a>Create Test PVC</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: test-cephfs-pvc</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">  storageClassName: rook-cephfs</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f pvc-cephfs-test.yaml</span><br><span class="line">kubectl get pvc -A</span><br><span class="line">kubectl delete -f pvc-cephfs-test.yaml</span><br></pre></td></tr></table></figure><p>To expose the Ceph dashboard via an Ingress, you can apply one of the following methods based on your cluster configuration and requirements. Below are three typical options for exposing the dashboard</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">dashboard-external-https.yaml</span><br><span class="line">dashboard-ingress-https.yaml</span><br><span class="line">dashboard-loadbalancer.yaml</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Get the default password of the dashboard</span></span><br><span class="line">kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=<span class="string">&quot;&#123;[&#x27;data&#x27;][&#x27;password&#x27;]&#125;&quot;</span>|<span class="built_in">base64</span> --decode &amp;&amp; <span class="built_in">echo</span></span><br></pre></td></tr></table></figure><h2 id="Join-the-ceph-cluster-when-adding-a-new-node"><a href="#Join-the-ceph-cluster-when-adding-a-new-node" class="headerlink" title="Join the ceph cluster when adding a new node"></a>Join the ceph cluster when adding a new node</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tag new node</span></span><br><span class="line">kubectl label node [node-name] role=rook-osd-node</span><br><span class="line"></span><br><span class="line"><span class="comment"># restart operator</span></span><br><span class="line">kubectl delete pod -n rook-ceph $(kubectl get pod -n rook-ceph | grep operator | awk <span class="string">&#x27;&#123;print$1&#125;&#x27;</span>)</span><br></pre></td></tr></table></figure></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://blog.2nfree.com/en-us">komorebi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://blog.2nfree.com/en-us/deploy-rook-ceph-on-k8s/">https://blog.2nfree.com/en-us/deploy-rook-ceph-on-k8s/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/en-us/tags/Kubernetes/">Kubernetes</a><a class="post-meta__tags" href="/en-us/tags/Storage/">Storage</a><a class="post-meta__tags" href="/en-us/tags/Ceph/">Ceph</a></div><div class="post-share"><div class="social-share" data-image="/en-us/images/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/en-us/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css?v=1.1.4" media="print" onload='this.media="all"'><script src="/en-us/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js?v=1.1.4" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/en-us/deploy-k8s-with-kubeadm/" title="Deploy Kubernetes With Kubeadm"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Deploy Kubernetes With Kubeadm</div></div><div class="info-2"><div class="info-item-1">This document provides a step-by-step guide to deploying a Kubernetes cluster using Kubeadm. The deployment process includes setting up the control plane node and worker nodes, and verifying the cluster's functionality.</div></div></div></a><a class="pagination-related" href="/en-us/deploy-doris/" title="Deploy Doris"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Deploy Doris</div></div><div class="info-2"><div class="info-item-1">This document introduces how to deploy a Doris cluster on a server.</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/en-us/deploy-ceph-by-cephadm/" title="Kubernetes 接入基于 Cephadm 部署的 Ceph 集群"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-12</div><div class="info-item-2">Kubernetes 接入基于 Cephadm 部署的 Ceph 集群</div></div><div class="info-2"><div class="info-item-1">Ceph 是一个分布式存储系统，诞生于 2004 年，最早致力于开发下一代高性能分布式文件系统的项目。经过多年的发展之后，已得到众多云计算和存储厂商的支持，成为应用最广泛的开源分布式存储平台。之前我们讲过如何在 Kubernetes 中部署 Ceph 集群并使用 Rook 接入，本篇文章我们将会讲解如何将 Ceph 集群部署在外部，并使用 Rook 接入外部的 Ceph。</div></div></div></a><a class="pagination-related" href="/en-us/volume-snapshots-with-rook-ceph/" title="Rook-ceph 开启卷快照功能"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-08</div><div class="info-item-2">Rook-ceph 开启卷快照功能</div></div><div class="info-2"><div class="info-item-1">VolumeSnapshot 是用户对卷快照的请求。它类似于 PersistentVolumeClaim，使用 VolumeSnapshot 可以用于对 PVC 进行快照备份，VolumeSnapshot 功能支持 CSI v1.0 及更高版本。它在 Kubernetes v1.12 中作为 Alpha 功能引入，并在 Kubernetes 1.17 中提升为 Beta 功能。在 Kubernetes 1.20 中，卷快照功能移至 GA。</div></div></div></a><a class="pagination-related" href="/en-us/ceph-osd-down/" title="Ceoh 集群 OSD Down 问题解决"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-13</div><div class="info-item-2">Ceoh 集群 OSD Down 问题解决</div></div><div class="info-2"><div class="info-item-1">记录一次 Ceph OSD down 的问题，将故障 OSD 对应磁盘还原成裸盘重新接入集群。</div></div></div></a></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/en-us/images/avatar.png" onerror='this.onerror=null,this.src="/en-us/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">komorebi</div><div class="author-info-description"></div><div class="site-data"><a href="/en-us/archives/"><div class="headline">Articles</div><div class="length-num">30</div></a><a href="/en-us/tags/"><div class="headline">Tags</div><div class="length-num">17</div></a><a href="/en-us/categories/"><div class="headline">Categories</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/2nfree"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/2nfree" target="_blank" title="Github"><i class="fab fa-github" style="color:#24292e"></i></a><a class="social-icon" href="mailto:komorebi2333@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color:#ffa07a"></i></a><a class="social-icon" href="https://twitter.com/2Nfree" target="_blank" title="Twitter"><i class="fa-brands fa-x-twitter" style="color:#4a7dbe"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Foreword"><span class="toc-number">1.</span> <span class="toc-text">Foreword</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Persistent-Storage"><span class="toc-number">1.1.</span> <span class="toc-text">Persistent Storage</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ceph"><span class="toc-number">1.2.</span> <span class="toc-text">Ceph</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rook"><span class="toc-number">1.3.</span> <span class="toc-text">Rook</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Prepare"><span class="toc-number">2.</span> <span class="toc-text">Prepare</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Disk"><span class="toc-number">2.1.</span> <span class="toc-text">Disk</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Install"><span class="toc-number">3.</span> <span class="toc-text">Install</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Deploy-Rook-Operator"><span class="toc-number">3.1.</span> <span class="toc-text">Deploy Rook Operator</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deploy-rook-ceph"><span class="toc-number">3.2.</span> <span class="toc-text">Deploy rook-ceph</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Check"><span class="toc-number">3.3.</span> <span class="toc-text">Check</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#StorageClass"><span class="toc-number">3.4.</span> <span class="toc-text">StorageClass</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CephFS"><span class="toc-number">3.4.1.</span> <span class="toc-text">CephFS</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Create-a-File-System-Pool"><span class="toc-number">3.4.1.1.</span> <span class="toc-text">Create a File System Pool</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Create-StorageClass"><span class="toc-number">3.4.1.2.</span> <span class="toc-text">Create StorageClass</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Set-Default-StorageClass"><span class="toc-number">3.4.1.3.</span> <span class="toc-text">Set Default StorageClass</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Create-Test-PVC"><span class="toc-number">3.4.1.4.</span> <span class="toc-text">Create Test PVC</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Join-the-ceph-cluster-when-adding-a-new-node"><span class="toc-number">3.5.</span> <span class="toc-text">Join the ceph cluster when adding a new node</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/en-us/kubernetes-logging-collection-5/" title="Kubernetes 日志收集（五）- 使用 Kafka 做中间层">Kubernetes 日志收集（五）- 使用 Kafka 做中间层</a><time datetime="2024-09-23T07:33:32.000Z" title="Created 2024-09-23 15:33:32">2024-09-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/en-us/some-ways-enhance-wsl-experience/" title="Some Ways to Enhance Your WSL Experience">Some Ways to Enhance Your WSL Experience</a><time datetime="2024-08-15T07:25:56.000Z" title="Created 2024-08-15 15:25:56">2024-08-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/en-us/cicd-in-kubernetes-based-jenkins-2/" title="从零实现CI/CD（二）- Jenkins 配置流水线">从零实现CI/CD（二）- Jenkins 配置流水线</a><time datetime="2024-07-04T07:41:11.000Z" title="Created 2024-07-04 15:41:11">2024-07-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/en-us/kubernetes-logging-collection-4/" title="Kubernetes 日志收集（四）- 基于 Fluent-bit Daemonset 的日志收集">Kubernetes 日志收集（四）- 基于 Fluent-bit Daemonset 的日志收集</a><time datetime="2024-05-22T10:26:58.000Z" title="Created 2024-05-22 18:26:58">2024-05-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/en-us/kubernetes-logging-collection-3/" title="Kubernetes 日志收集（三）- Logging operator 中使用 concat 多行合并相关问题">Kubernetes 日志收集（三）- Logging operator 中使用 concat 多行合并相关问题</a><time datetime="2024-05-13T04:26:58.000Z" title="Created 2024-05-13 12:26:58">2024-05-13</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By komorebi</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/en-us/js/utils.js?v=5.3.2"></script><script src="/en-us/js/main.js?v=5.3.2"></script><div class="js-pjax"><script>(()=>{const e="shuoshuo"===GLOBAL_CONFIG_SITE.pageType,t=e=>"dark"===e?"dark":"light",s=(s=document,a)=>{const n=e?{"data-mapping":"specific","data-term":a}:{"data-mapping":"pathname"},o=(e=>{const t=document.createElement("script");return Object.entries(e).forEach(([e,s])=>{t.setAttribute(e,s)}),t})({src:"https://giscus.app/client.js","data-repo":"2nfree/2nfree.github.io","data-repo-id":"R_kgDOJEANRA","data-category-id":"DIC_kwDOJEANRM4CcNhM","data-theme":t(document.documentElement.getAttribute("data-theme")),"data-reactions-enabled":"1",crossorigin:"anonymous",async:!0,...n});s.querySelector("#giscus-wrap").appendChild(o),e&&(window.shuoshuoComment.destroyGiscus=()=>{s.children.length&&(s.innerHTML="",s.classList.add("no-comment"))})};btf.addGlobalFn("themeChange",e=>{const s=document.querySelector("#giscus-wrap iframe");if(s){const a={giscus:{setConfig:{theme:t(e)}}};s.contentWindow.postMessage(a,"https://giscus.app")}},"giscus"),e?window.shuoshuoComment={loadComment:s}:btf.loadComment(document.getElementById("giscus-wrap"),s)})()</script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> Loading Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/en-us/js/search/local-search.js?v=5.3.2"></script></div></div></body></html>